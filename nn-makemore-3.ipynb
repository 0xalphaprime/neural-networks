{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## makemore 3 \n",
    "\n",
    "__Batch Normalization__\n",
    "[Batch Normalization Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/pdf/1502.03167.pdf)\n",
    "\n",
    "The research paper titled \"Deep Residual Learning for Image Recognition\" presents a breakthrough innovation in training deep neural networks for image recognition tasks. This innovation involves using very deep neural networks with \"shortcut connections\" (also known as \"skip connections\" or \"identity mappings\") to overcome the problem of vanishing gradients. \n",
    "\n",
    "Simply put, the problem of vanishing gradients arises when the gradients of the loss function with respect to the weights become very small as they are propagated backwards through multiple layers of a deep neural network. This problem makes it difficult to train neural networks with many layers, as the weights of the early layers do not get updated effectively. One common solution to this problem is to use a technique called \"batch normalization\" that normalizes the inputs to each layer. However, this technique has its own limitations and does not always work well in practice.\n",
    "\n",
    "The innovation presented in this paper involves using \"shortcut connections\" to enable the gradients to propagate more easily through the network. These connections allow the input of a layer to be added to the output of another layer further down the network, creating a \"residual\" of the input that can bypass one or more layers. The key insight behind this technique is that if the skipped layers can approximate an identity function, then the network can be more easily optimized to learn the desired mapping between the input and output.\n",
    "\n",
    "The authors demonstrate the effectiveness of their approach on the challenging ImageNet dataset, where they achieve state-of-the-art results using very deep neural networks with up to 152 layers. They also show that their approach is effective for a wide range of other image recognition tasks, including object detection and semantic segmentation.\n",
    "\n",
    "Overall, the paper provides a significant contribution to the field of deep learning by providing a new approach to training very deep neural networks that can optimize the learning process more effectively than previous techniques. This innovation has many potential applications in computer vision and other fields that rely on deep neural networks for learning complex mappings between inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['emma',\n",
       " 'olivia',\n",
       " 'ava',\n",
       " 'isabella',\n",
       " 'sophia',\n",
       " 'charlotte',\n",
       " 'mia',\n",
       " 'amelia',\n",
       " 'harper',\n",
       " 'evelyn']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in all of the data\n",
    "words = open('data/names.txt', 'r').read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32033"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "# build the vocab of characters and mappings to and from integers\n",
    "\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # this is the length of the sequences we will use for training\n",
    "\n",
    "def build_dataset(words):\n",
    "\n",
    "    X, Y = [], []\n",
    "\n",
    "    for w in words:\n",
    "        context = [0] * block_size\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            context = context[1:] + [ix] # shift the context by one character\n",
    "    \n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    print(X.shape, Y.shape)\n",
    "    return X, Y\n",
    "\n",
    "import random \n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(len(words) * 0.8)\n",
    "n2 = int(len(words) * 0.9)\n",
    "\n",
    "Xtr, Ytr = build_dataset(words[:n1]) # training set 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2]) # dev set 10%\n",
    "Xte, Yte = build_dataset(words[n2:]) # test set 10%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12097\n"
     ]
    }
   ],
   "source": [
    "# MLP revisited \n",
    "\n",
    "n_embd = 10 # embedding dimension\n",
    "n_hidden = 200 # hidden dimension\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # this is for reproducibility\n",
    "C = torch.randn((vocab_size, n_embd), generator=g) # the embedding matrix\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g)  * (5/3) * ((n_embd * block_size) ** 0.5)# the first weight matrix\n",
    "# b1 = torch.randn((n_hidden), generator=g) * 0.01 # the first bias vector\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g) * 0.01 # the second weight matrix\n",
    "b2 = torch.randn((vocab_size), generator=g) * 0 # the second bias vector\n",
    "\n",
    "#batchNorm parameters\n",
    "bngain = torch.ones((1, n_hidden)) # gain parameter\n",
    "bnbias = torch.zeros((1, n_hidden)) # bias parameter\n",
    "bnmean_running = torch.zeros((1, n_hidden)) # running mean\n",
    "bnstd_running = torch.ones((1, n_hidden)) # running std\n",
    "\n",
    "parameters = [C, W1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))  # number of parameters in total \n",
    "for p in parameters:\n",
    "    p.requires_grad_() # we need gradients w.r.t. all parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m lr \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39m10000\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0.01\u001b[39m \u001b[39m# learning rate decay\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mfor\u001b[39;00m p \u001b[39min\u001b[39;00m parameters:\n\u001b[0;32m---> 38\u001b[0m     p\u001b[39m.\u001b[39mdata \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m-\u001b[39;49mlr \u001b[39m*\u001b[39;49m p\u001b[39m.\u001b[39;49mgrad\n\u001b[1;32m     40\u001b[0m \u001b[39m# track stats\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m10000\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# optimization \n",
    "\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "lossi = []\n",
    "\n",
    "for i in range (max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g) # random indices\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # construct minibatch\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # get the embeddings for the minibatch\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # linear layer\n",
    "    hpreact = embcat @ W1 # preactivation\n",
    "    # batchnorm\n",
    "    bnmeani = hpreact.mean(0, keepdim=True) # minibatch mean\n",
    "    bnstdi = hpreact.std(0, keepdim=True) # minibatch std\n",
    "    hpreact = bngain - (hpreact - bnmeani) / (bnstdi + 1e-8) # normalize\n",
    "    with torch.no_grad():\n",
    "        bnmean_running = 0.99 * bnmean_running + 0.01 * bnmeani # update running mean\n",
    "        bnstd_running = 0.99 * bnstd_running + 0.01 * bnstdi # update running std\n",
    "    # nonlinearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # logits for the output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # cross-entropy loss function \n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "    loss.backward() # autograd computes all the gradients\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 10000 else 0.01 # learning rate decay\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0:\n",
    "        print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-ml-050923",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
